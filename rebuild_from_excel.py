#!/usr/bin/env python3
"""
Script pour reconstruire proprement les donnÃ©es depuis l'Excel source
"""

import pandas as pd
import psycopg2
from psycopg2.extras import RealDictCursor
import json

def load_excel_data():
    """Charger et nettoyer les donnÃ©es Excel"""
    print("ğŸ“Š CHARGEMENT DES DONNÃ‰ES EXCEL")
    print("=" * 40)
    
    excel_path = "exports/template_import_v22_WORKFLOW_READY.xlsx"
    
    # Charger les feuilles
    teachers_df = pd.read_excel(excel_path, sheet_name='Teachers')
    teacher_subjects_df = pd.read_excel(excel_path, sheet_name='Teacher_Subjects')
    parallel_groups_df = pd.read_excel(excel_path, sheet_name='Parallel_Groups')
    constraints_df = pd.read_excel(excel_path, sheet_name='Constraints')
    
    print(f"âœ“ Teachers: {len(teachers_df)} lignes")
    print(f"âœ“ Teacher_Subjects: {len(teacher_subjects_df)} lignes")
    print(f"âœ“ Parallel_Groups: {len(parallel_groups_df)} lignes")
    print(f"âœ“ Constraints: {len(constraints_df)} lignes")
    print("")
    
    return {
        'teachers': teachers_df,
        'teacher_subjects': teacher_subjects_df,
        'parallel_groups': parallel_groups_df,
        'constraints': constraints_df
    }

def analyze_parallel_groups(data):
    """Analyser les groupes parallÃ¨les pour dÃ©tecter les doublons"""
    print("ğŸ” ANALYSE DES GROUPES PARALLÃˆLES")
    print("=" * 41)
    
    teacher_subjects = data['teacher_subjects']
    parallel_groups = data['parallel_groups']
    
    # Analyser TOUS les cours pour dÃ©tecter les vrais groupes parallÃ¨les
    # Un groupe parallÃ¨le = mÃªme matiÃ¨re, mÃªme niveau, mÃªmes classes, plusieurs profs
    all_courses = teacher_subjects.copy()
    
    # Grouper par matiÃ¨re/niveau/classes pour trouver les cours avec plusieurs profs
    grouped = all_courses.groupby(['Subject', 'Grade', 'Class List']).agg({
        'Teacher Name': lambda x: ', '.join(sorted(set(x))),  # ConcatÃ©ner tous les profs uniques
        'Hours': 'first'  # Les heures devraient Ãªtre identiques
    }).reset_index()
    
    # Ajouter le nombre de profs
    grouped['Nb_Teachers'] = grouped['Teacher Name'].apply(lambda x: len(x.split(', ')))
    
    # SÃ©parer les cours parallÃ¨les (plusieurs profs) et individuels (un seul prof)
    parallel_courses = grouped[grouped['Nb_Teachers'] > 1]
    individual_courses = grouped[grouped['Nb_Teachers'] == 1]
    
    print(f"Cours trouvÃ©s: {len(grouped)} au total")
    print(f"  - Cours parallÃ¨les (plusieurs profs): {len(parallel_courses)}")
    print(f"  - Cours individuels (un seul prof): {len(individual_courses)}")
    
    print("\nTop 10 des vrais groupes parallÃ¨les:")
    for _, row in parallel_courses.head(10).iterrows():
        print(f"  {row['Subject']} - {row['Grade']} - {row['Class List']}")
        print(f"    {row['Nb_Teachers']} profs: {row['Teacher Name']}")
        print(f"    {row['Hours']}h")
    print("")
    
    return parallel_courses

def calculate_real_load(data):
    """Calculer la vraie charge en regroupant correctement les cours parallÃ¨les"""
    print("ğŸ“Š CALCUL DE LA VRAIE CHARGE")
    print("=" * 33)
    
    teacher_subjects = data['teacher_subjects']
    
    # Regrouper TOUS les cours par (Subject, Grade, Class List)
    print("Regroupement des cours par matiÃ¨re/niveau/classes...")
    
    grouped = teacher_subjects.groupby(['Subject', 'Grade', 'Class List']).agg({
        'Teacher Name': lambda x: ', '.join(sorted(set(x))),  # Tous les profs uniques
        'Hours': 'first'  # Les heures devraient Ãªtre identiques pour un mÃªme groupe
    }).reset_index()
    
    # Identifier parallÃ¨les vs individuels
    grouped['Nb_Teachers'] = grouped['Teacher Name'].apply(lambda x: len(x.split(', ')))
    grouped['Is_Parallel'] = grouped['Nb_Teachers'] > 1
    
    parallel_courses = grouped[grouped['Is_Parallel']]
    individual_courses = grouped[~grouped['Is_Parallel']]
    
    total_parallel_hours = parallel_courses['Hours'].sum()
    total_individual_hours = individual_courses['Hours'].sum()
    total_courses = len(grouped)
    total_hours = total_parallel_hours + total_individual_hours
    
    print(f"  Cours parallÃ¨les: {len(parallel_courses)} cours, {total_parallel_hours}h")
    print(f"  Cours individuels: {len(individual_courses)} cours, {total_individual_hours}h")
    print(f"  TOTAL: {total_courses} cours, {total_hours}h")
    print("")
    
    # Calculer la faisabilitÃ©
    slots_available = 57  # Nous savons qu'il y en a 57
    utilization = (total_hours / slots_available) * 100
    
    print(f"ğŸ“ˆ FAISABILITÃ‰:")
    print(f"  Heures Ã  planifier: {total_hours}")
    print(f"  CrÃ©neaux disponibles: {slots_available}")
    print(f"  Taux d'utilisation: {utilization:.1f}%")
    
    if utilization > 100:
        print(f"  âŒ IMPOSSIBLE - {utilization-100:.1f}% de surcharge")
    elif utilization > 85:
        print(f"  âš ï¸  DIFFICILE - TrÃ¨s proche de la limite")
    else:
        print(f"  âœ… FAISABLE")
    
    print("")
    
    return {
        'parallel_courses': parallel_courses,
        'individual_courses': individual_courses,
        'all_courses': grouped,
        'total_hours': total_hours,
        'total_courses': total_courses,
        'utilization': utilization
    }

def rebuild_solver_input(clean_data):
    """Reconstruire solver_input avec les donnÃ©es nettoyÃ©es et support correct des cours parallÃ¨les"""
    print("ğŸ”§ RECONSTRUCTION DE SOLVER_INPUT")
    print("=" * 42)
    
    db_config = {
        "host": "localhost",
        "database": "school_scheduler", 
        "user": "admin",
        "password": "school123"
    }
    
    try:
        conn = psycopg2.connect(**db_config)
        cur = conn.cursor()
        
        # Sauvegarder l'ancien
        cur.execute("DROP TABLE IF EXISTS solver_input_before_rebuild;")
        cur.execute("CREATE TABLE solver_input_before_rebuild AS SELECT * FROM solver_input;")
        
        # Vider solver_input
        cur.execute("TRUNCATE solver_input;")
        
        # Ajouter la colonne teacher_names si elle n'existe pas
        cur.execute("""
            ALTER TABLE solver_input 
            ADD COLUMN IF NOT EXISTS teacher_names VARCHAR(500);
        """)
        
        # InsÃ©rer TOUS les cours avec le bon marquage parallÃ¨le/individuel
        print("Insertion des cours...")
        course_id = 1
        total_courses = len(clean_data['all_courses'])
        
        for idx, (_, course) in enumerate(clean_data['all_courses'].iterrows()):
            if idx % 10 == 0:
                print(f"  Progression: {idx}/{total_courses} cours...")
            
            # InsÃ©rer avec teacher_names seulement
            cur.execute("""
                INSERT INTO solver_input (course_type, teacher_names, subject, grade, class_list, hours, is_parallel, group_id)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
            """, (
                'regular',
                course['Teacher Name'],  # Tous les profs (dÃ©jÃ  concatÃ©nÃ©s)
                course['Subject'],
                course['Grade'], 
                course['Class List'],
                course['Hours'],
                course['Is_Parallel'],  # True si plusieurs profs
                course_id if course['Is_Parallel'] else None  # group_id seulement pour les parallÃ¨les
            ))
            course_id += 1
        
        print(f"âœ“ {total_courses} cours insÃ©rÃ©s")
        
        conn.commit()
        
        # VÃ©rifier le rÃ©sultat
        cur.execute("SELECT COUNT(*), SUM(hours), COUNT(*) FILTER (WHERE is_parallel = TRUE) as parallel_count FROM solver_input;")
        result = cur.fetchone()
        
        print(f"âœ“ Nouveau solver_input: {result[0]} cours, {result[1]}h")
        print(f"  dont {result[2]} cours parallÃ¨les")
        print("")
        
        cur.close()
        conn.close()
        
        return True
        
    except Exception as e:
        print(f"âŒ Erreur: {e}")
        return False

def main():
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘       RECONSTRUCTION DEPUIS DONNÃ‰ES EXCEL              â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print("")
    
    # 1. Charger Excel
    data = load_excel_data()
    
    # 2. Analyser les groupes parallÃ¨les
    duplicates = analyze_parallel_groups(data)
    
    # 3. Calculer la vraie charge
    clean_data = calculate_real_load(data)
    
    # 4. Reconstruire si acceptable
    if clean_data['utilization'] <= 1500:  # Seuil augmentÃ© temporairement
        print("ğŸš€ RECONSTRUCTION DE LA BASE DE DONNÃ‰ES")
        print("=" * 47)
        
        if rebuild_solver_input(clean_data):
            print("âœ… Reconstruction rÃ©ussie!")
            print("")
            print("ğŸ¯ PROCHAINES Ã‰TAPES:")
            print("1. Tester la gÃ©nÃ©ration:")
            print("   curl -X POST 'http://localhost:8000/generate_schedule' -H 'Content-Type: application/json' -d '{\"time_limit\": 1200}'")
            print("")
            print("2. Si Ã§a Ã©choue encore, rÃ©duire davantage les donnÃ©es")
        else:
            print("âŒ Ã‰chec de la reconstruction")
    else:
        print("âš ï¸  DonnÃ©es encore trop volumineuses pour la gÃ©nÃ©ration")
        print("   ConsidÃ©rez:")
        print("   - RÃ©duire le nombre d'heures par matiÃ¨re")
        print("   - Tester sur quelques niveaux seulement")
        print("   - Augmenter le nombre de crÃ©neaux disponibles")

if __name__ == "__main__":
    main()

