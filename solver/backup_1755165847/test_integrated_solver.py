#!/usr/bin/env python3
"""
test_integrated_solver.py - Script de test pour le solver intÃ©grÃ©
Teste les 193 cours avec validation complÃ¨te
"""
import sys
import os
import logging
import time
import requests
import json
from datetime import datetime

# Configuration du logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class IntegratedSolverTester:
    """Classe de test pour le solver intÃ©grÃ©"""
    
    def __init__(self, base_url="http://localhost:8000"):
        self.base_url = base_url
        self.test_results = {}
        
    def test_api_availability(self):
        """VÃ©rifier que l'API est accessible"""
        logger.info("=== TEST: DisponibilitÃ© de l'API ===")
        
        try:
            response = requests.get(f"{self.base_url}/", timeout=10)
            if response.status_code == 200:
                logger.info("âœ“ API accessible")
                return True
            else:
                logger.error(f"âœ— API non accessible: status {response.status_code}")
                return False
        except requests.exceptions.RequestException as e:
            logger.error(f"âœ— Erreur connexion API: {e}")
            return False
    
    def test_data_availability(self):
        """VÃ©rifier que les donnÃ©es solver_input sont disponibles"""
        logger.info("=== TEST: DisponibilitÃ© des donnÃ©es solver_input ===")
        
        try:
            response = requests.get(f"{self.base_url}/api/stats", timeout=10)
            if response.status_code == 200:
                stats = response.json()
                logger.info("âœ“ Statistiques disponibles:")
                for key, value in stats.items():
                    if 'solver_input' in key or 'courses' in key:
                        logger.info(f"  - {key}: {value}")
                return True
            else:
                logger.warning("âš  Pas de statistiques disponibles")
                return True  # Continue anyway
        except Exception as e:
            logger.error(f"âœ— Erreur rÃ©cupÃ©ration stats: {e}")
            return False
    
    def test_integrated_solver_generation(self, time_limit=600):
        """Tester la gÃ©nÃ©ration avec le solver intÃ©grÃ©"""
        logger.info("=== TEST: GÃ©nÃ©ration avec solver intÃ©grÃ© ===")
        logger.info(f"Limite de temps: {time_limit} secondes")
        
        payload = {
            "time_limit": time_limit,
            "advanced": True,
            "minimize_gaps": True,
            "friday_short": True
        }
        
        start_time = time.time()
        
        try:
            response = requests.post(
                f"{self.base_url}/generate_schedule_integrated",
                json=payload,
                timeout=time_limit + 60  # Timeout un peu plus long que le solver
            )
            
            generation_time = time.time() - start_time
            
            if response.status_code == 200:
                result = response.json()
                logger.info("âœ… GÃ‰NÃ‰RATION RÃ‰USSIE!")
                logger.info(f"  - Temps total: {generation_time:.2f}s")
                logger.info(f"  - Temps solver: {result.get('solve_time', 0):.2f}s")
                logger.info(f"  - Schedule ID: {result.get('schedule_id')}")
                logger.info(f"  - QualitÃ©: {result.get('quality_score', 0)}/100")
                logger.info(f"  - Trous: {result.get('gaps_count', 0)}")
                logger.info(f"  - Sync parallÃ¨le: {'âœ“' if result.get('parallel_sync_ok', False) else 'âœ—'}")
                logger.info(f"  - Cours total: {result.get('total_courses', 0)}")
                logger.info(f"  - Groupes parallÃ¨les: {result.get('parallel_groups', 0)}")
                
                self.test_results['integrated_solver'] = {
                    'success': True,
                    'generation_time': generation_time,
                    'solve_time': result.get('solve_time', 0),
                    'schedule_id': result.get('schedule_id'),
                    'quality_score': result.get('quality_score', 0),
                    'gaps_count': result.get('gaps_count', 0),
                    'parallel_sync_ok': result.get('parallel_sync_ok', False),
                    'total_courses': result.get('total_courses', 0),
                    'parallel_groups': result.get('parallel_groups', 0)
                }
                
                return result.get('schedule_id')
                
            else:
                logger.error(f"âœ— GÃ©nÃ©ration Ã©chouÃ©e: {response.status_code}")
                if response.text:
                    logger.error(f"  DÃ©tail: {response.text}")
                
                self.test_results['integrated_solver'] = {
                    'success': False,
                    'error': f"HTTP {response.status_code}: {response.text[:200]}"
                }
                return None
                
        except requests.exceptions.Timeout:
            logger.error(f"âœ— Timeout aprÃ¨s {time_limit + 60}s")
            self.test_results['integrated_solver'] = {
                'success': False,
                'error': 'Timeout'
            }
            return None
        except Exception as e:
            logger.error(f"âœ— Erreur gÃ©nÃ©ration: {e}")
            self.test_results['integrated_solver'] = {
                'success': False,
                'error': str(e)
            }
            return None
    
    def test_schedule_retrieval(self, schedule_id):
        """Tester la rÃ©cupÃ©ration de l'emploi du temps"""
        if not schedule_id:
            logger.warning("Pas de schedule_id pour le test de rÃ©cupÃ©ration")
            return False
            
        logger.info(f"=== TEST: RÃ©cupÃ©ration emploi du temps ID={schedule_id} ===")
        
        try:
            response = requests.get(f"{self.base_url}/api/schedule/{schedule_id}", timeout=30)
            
            if response.status_code == 200:
                schedule_data = response.json()
                if schedule_data.get('success'):
                    entries_count = schedule_data.get('total_entries', 0)
                    days = len(schedule_data.get('days', []))
                    
                    logger.info("âœ“ Emploi du temps rÃ©cupÃ©rÃ©:")
                    logger.info(f"  - EntrÃ©es: {entries_count}")
                    logger.info(f"  - Jours: {days}")
                    
                    # Analyser les cours parallÃ¨les
                    grid = schedule_data.get('schedule_grid', {})
                    parallel_found = 0
                    for day, day_data in grid.items():
                        for period, period_data in day_data.items():
                            for class_entry in period_data:
                                if class_entry.get('is_parallel'):
                                    parallel_found += 1
                    
                    logger.info(f"  - Cours parallÃ¨les dÃ©tectÃ©s: {parallel_found}")
                    
                    self.test_results['schedule_retrieval'] = {
                        'success': True,
                        'entries_count': entries_count,
                        'days_count': days,
                        'parallel_courses': parallel_found
                    }
                    
                    return True
                else:
                    logger.error(f"âœ— Erreur dans les donnÃ©es: {schedule_data.get('error')}")
                    return False
            else:
                logger.error(f"âœ— Ã‰chec rÃ©cupÃ©ration: {response.status_code}")
                return False
                
        except Exception as e:
            logger.error(f"âœ— Erreur rÃ©cupÃ©ration: {e}")
            return False
    
    def test_quality_metrics(self):
        """Valider les mÃ©triques de qualitÃ©"""
        logger.info("=== TEST: Validation des mÃ©triques de qualitÃ© ===")
        
        integrated_result = self.test_results.get('integrated_solver', {})
        
        if not integrated_result.get('success', False):
            logger.error("âœ— Impossible de valider - gÃ©nÃ©ration Ã©chouÃ©e")
            return False
        
        quality_score = integrated_result.get('quality_score', 0)
        gaps_count = integrated_result.get('gaps_count', float('inf'))
        parallel_sync_ok = integrated_result.get('parallel_sync_ok', False)
        
        # CritÃ¨res de qualitÃ©
        quality_pass = quality_score >= 85
        gaps_pass = gaps_count <= (integrated_result.get('total_courses', 200) * 0.05)  # < 5% de trous
        sync_pass = parallel_sync_ok
        
        logger.info(f"Score de qualitÃ©: {quality_score}/100 {'âœ“' if quality_pass else 'âœ—'}")
        logger.info(f"Nombre de trous: {gaps_count} {'âœ“' if gaps_pass else 'âœ—'}")
        logger.info(f"Synchronisation parallÃ¨le: {'âœ“' if sync_pass else 'âœ—'}")
        
        overall_pass = quality_pass and gaps_pass and sync_pass
        
        self.test_results['quality_validation'] = {
            'quality_score': quality_score,
            'quality_pass': quality_pass,
            'gaps_count': gaps_count,
            'gaps_pass': gaps_pass,
            'parallel_sync_ok': sync_pass,
            'overall_pass': overall_pass
        }
        
        if overall_pass:
            logger.info("âœ… TOUS LES CRITÃˆRES DE QUALITÃ‰ RESPECTÃ‰S")
        else:
            logger.error("âœ— CERTAINS CRITÃˆRES DE QUALITÃ‰ NON RESPECTÃ‰S")
        
        return overall_pass
    
    def compare_with_other_solvers(self):
        """Comparer avec les autres solvers disponibles"""
        logger.info("=== TEST: Comparaison avec autres solvers ===")
        
        other_endpoints = [
            "/generate_schedule",
            "/generate_schedule_fixed",
            "/generate_schedule_corrected"
        ]
        
        comparison_results = {}
        
        for endpoint in other_endpoints:
            logger.info(f"Test {endpoint}...")
            
            payload = {
                "time_limit": 300,  # Temps rÃ©duit pour les comparaisons
                "advanced": True
            }
            
            try:
                start_time = time.time()
                response = requests.post(f"{self.base_url}{endpoint}", json=payload, timeout=350)
                generation_time = time.time() - start_time
                
                if response.status_code == 200:
                    result = response.json()
                    comparison_results[endpoint] = {
                        'success': True,
                        'generation_time': generation_time,
                        'quality_score': result.get('quality_score', 0),
                        'message': result.get('message', 'OK')[:100]
                    }
                    logger.info(f"  âœ“ {endpoint}: {generation_time:.1f}s, qualitÃ©: {result.get('quality_score', 0)}")
                else:
                    comparison_results[endpoint] = {
                        'success': False,
                        'error': f"HTTP {response.status_code}"
                    }
                    logger.info(f"  âœ— {endpoint}: Ã‰chec {response.status_code}")
                    
            except Exception as e:
                comparison_results[endpoint] = {
                    'success': False,
                    'error': str(e)[:100]
                }
                logger.info(f"  âœ— {endpoint}: Erreur {str(e)[:50]}")
        
        self.test_results['comparison'] = comparison_results
        return comparison_results
    
    def generate_report(self):
        """GÃ©nÃ©rer un rapport de test"""
        logger.info("=== RAPPORT DE TEST FINAL ===")
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = f"test_report_{timestamp}.json"
        
        # Rapport console
        print("\n" + "="*60)
        print("RAPPORT DE TEST DU SOLVER INTÃ‰GRÃ‰")
        print("="*60)
        
        integrated = self.test_results.get('integrated_solver', {})
        if integrated.get('success'):
            print(f"âœ… GÃ©nÃ©ration intÃ©grÃ©e: SUCCÃˆS")
            print(f"   - Temps: {integrated.get('solve_time', 0):.2f}s")
            print(f"   - QualitÃ©: {integrated.get('quality_score', 0)}/100")
            print(f"   - Trous: {integrated.get('gaps_count', 0)}")
            print(f"   - Sync parallÃ¨le: {'Oui' if integrated.get('parallel_sync_ok', False) else 'Non'}")
            print(f"   - Cours traitÃ©s: {integrated.get('total_courses', 0)}")
        else:
            print(f"âŒ GÃ©nÃ©ration intÃ©grÃ©e: Ã‰CHEC")
            print(f"   - Erreur: {integrated.get('error', 'Inconnue')}")
        
        quality = self.test_results.get('quality_validation', {})
        if quality.get('overall_pass'):
            print(f"âœ… CritÃ¨res de qualitÃ©: RESPECTÃ‰S")
        else:
            print(f"âŒ CritÃ¨res de qualitÃ©: NON RESPECTÃ‰S")
        
        comparison = self.test_results.get('comparison', {})
        successful_alternatives = sum(1 for r in comparison.values() if r.get('success', False))
        print(f"ğŸ“Š Autres solvers testÃ©s: {successful_alternatives}/{len(comparison)} fonctionnels")
        
        # Sauvegarde du rapport dÃ©taillÃ©
        try:
            full_report = {
                'timestamp': timestamp,
                'test_summary': {
                    'integrated_solver_success': integrated.get('success', False),
                    'quality_criteria_passed': quality.get('overall_pass', False),
                    'alternative_solvers_working': successful_alternatives,
                    'total_test_duration': time.time()
                },
                'detailed_results': self.test_results
            }
            
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(full_report, f, indent=2, ensure_ascii=False)
            
            print(f"ğŸ“„ Rapport dÃ©taillÃ©: {report_file}")
            
        except Exception as e:
            print(f"âš  Erreur sauvegarde rapport: {e}")
        
        print("="*60)
        
        return integrated.get('success', False) and quality.get('overall_pass', False)
    
    def run_full_test_suite(self):
        """ExÃ©cuter la suite de tests complÃ¨te"""
        logger.info("ğŸš€ DÃ‰MARRAGE DE LA SUITE DE TESTS COMPLÃˆTE")
        
        # Phase 1: Tests prÃ©liminaires
        if not self.test_api_availability():
            logger.error("Test abandonnÃ© - API non disponible")
            return False
        
        self.test_data_availability()
        
        # Phase 2: Test principal
        schedule_id = self.test_integrated_solver_generation()
        
        # Phase 3: Validation
        if schedule_id:
            self.test_schedule_retrieval(schedule_id)
        
        self.test_quality_metrics()
        
        # Phase 4: Comparaison
        self.compare_with_other_solvers()
        
        # Phase 5: Rapport
        return self.generate_report()


def main():
    """Point d'entrÃ©e principal"""
    print("Test du Solver IntÃ©grÃ© - Ã‰cole IsraÃ©lienne")
    print("Objectif: Valider la synchronisation parallÃ¨le et l'Ã©limination des trous")
    print("-" * 60)
    
    tester = IntegratedSolverTester()
    
    try:
        success = tester.run_full_test_suite()
        
        if success:
            print("\nğŸ‰ SUCCÃˆS: Le solver intÃ©grÃ© fonctionne correctement!")
            print("   Tous les critÃ¨res de qualitÃ© sont respectÃ©s.")
            sys.exit(0)
        else:
            print("\nâŒ Ã‰CHEC: Le solver intÃ©grÃ© ne rÃ©pond pas aux critÃ¨res.")
            print("   Consultez les logs pour plus de dÃ©tails.")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\nâ¹ Test interrompu par l'utilisateur")
        sys.exit(130)
    except Exception as e:
        logger.error(f"Erreur inattendue: {e}", exc_info=True)
        print(f"\nğŸ’¥ ERREUR CRITIQUE: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()