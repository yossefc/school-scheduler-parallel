#!/bin/bash
# ================================================================
# DOCKER-ENTRYPOINT-FIXED.SH
# Script de d√©marrage Docker corrig√© pour √©viter les duplications
# ================================================================

set -e

echo "üöÄ Starting Solver Service with duplication protection..."

# Variables d'environnement
DB_HOST=${DB_HOST:-postgres}
DB_PORT=${DB_PORT:-5432}
DB_NAME=${DB_NAME:-school_scheduler}
DB_USER=${DB_USER:-admin}
DB_PASS=${DB_PASS:-school123}

# Fonction pour ex√©cuter SQL de mani√®re s√©curis√©e
run_sql() {
    PGPASSWORD=$DB_PASS psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME -c "$1" 2>/dev/null
}

run_sql_file() {
    PGPASSWORD=$DB_PASS psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME -f "$1" 2>/dev/null
}

# Attendre que PostgreSQL soit pr√™t
echo "‚è≥ Waiting for PostgreSQL..."
while ! pg_isready -h $DB_HOST -p $DB_PORT -U $DB_USER > /dev/null 2>&1; do
    echo "   PostgreSQL not ready, waiting..."
    sleep 2
done
echo "‚úÖ PostgreSQL is ready!"

# ================================================================
# √âTAPE 0 : Initialisation du sch√©ma de base (si n√©cessaire)
# ================================================================
echo "üîç Checking if database schema is initialized..."

# V√©rifier si les tables de base existent
if ! run_sql "SELECT 1 FROM time_slots LIMIT 1;" >/dev/null 2>&1; then
    echo "üì• Database not initialized. Loading initial schema..."
    
    # Chemin vers le fichier schema.sql
    SCHEMA_FILE="/app/database/schema.sql"
    
    if [ -f "$SCHEMA_FILE" ]; then
        echo "   ‚ñ∂Ô∏è  Executing schema.sql..."
        if run_sql_file "$SCHEMA_FILE"; then
            echo "   ‚úÖ Schema loaded successfully!"
            
            # V√©rifier que les donn√©es de base sont bien l√†
            time_slots_count=$(run_sql "SELECT COUNT(*) FROM time_slots;" | grep -oE '[0-9]+' | tail -1)
            echo "   üìä Time slots created: $time_slots_count"
            
        else
            echo "   ‚ùå Failed to load schema!"
            exit 1
        fi
    else
        echo "   ‚ö†Ô∏è  Schema file not found at $SCHEMA_FILE"
        echo "   Creating minimal structure..."
        
        # Cr√©er au minimum les tables n√©cessaires
        run_sql "
        CREATE TABLE IF NOT EXISTS time_slots (
            slot_id SERIAL PRIMARY KEY,
            day_of_week INTEGER,
            period_number INTEGER,
            start_time TIME NOT NULL,
            end_time TIME NOT NULL,
            is_break BOOLEAN DEFAULT FALSE
        );
        
        CREATE TABLE IF NOT EXISTS classes (
            class_id SERIAL PRIMARY KEY,
            grade INTEGER NOT NULL,
            section VARCHAR(10) NOT NULL,
            class_name VARCHAR(50) UNIQUE NOT NULL,
            student_count INTEGER
        );
        
        CREATE TABLE IF NOT EXISTS teachers (
            teacher_id SERIAL PRIMARY KEY,
            teacher_name VARCHAR(100) UNIQUE NOT NULL,
            total_hours INTEGER,
            work_days VARCHAR(50),
            email VARCHAR(100),
            phone VARCHAR(20),
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );
        
        CREATE TABLE IF NOT EXISTS subjects (
            subject_id SERIAL PRIMARY KEY,
            subject_name VARCHAR(100) NOT NULL,
            subject_code VARCHAR(20) UNIQUE,
            category VARCHAR(50),
            difficulty_level INTEGER DEFAULT 3
        );"
        
        # Ins√©rer des cr√©neaux horaires simplifi√©s (p√©riodes 1-8)
        echo "   üìÖ Creating simple time slots (periods 1-8)..."
        run_sql "
        INSERT INTO time_slots (day_of_week, period_number, start_time, end_time, is_break)
        SELECT d, p, '00:00'::time, '00:00'::time, FALSE
        FROM generate_series(0,5) AS d      -- 0=Dimanche, 1=Lundi...5=Vendredi
        CROSS JOIN generate_series(1,8) AS p  -- P√©riodes 1 √† 8
        ON CONFLICT DO NOTHING;"
        
        # Ne pas cr√©er de classes de d√©monstration - elles seront g√©n√©r√©es automatiquement
        echo "   ‚ÑπÔ∏è  Classes will be auto-generated from teacher_load data..."
        
        echo "   ‚úÖ Minimal structure created!"
    fi
else
    echo "   ‚úÖ Database already initialized."
fi

# ================================================================
# √âTAPE 0.5 : Synchronisation automatique des classes depuis teacher_load
# ================================================================
echo "üîÑ Synchronizing classes from teacher_load data..."

# Extraire toutes les classes mentionn√©es dans teacher_load et les ins√©rer
run_sql "
INSERT INTO classes (grade, section, class_name, student_count)
SELECT 
    NULL AS grade,
    NULL AS section,
    TRIM(class_name) AS class_name,
    NULL AS student_count
FROM (
    SELECT DISTINCT unnest(string_to_array(class_list, ',')) AS class_name
    FROM teacher_load
    WHERE class_list IS NOT NULL 
      AND class_list != ''
      AND class_list != 'NULL'
) AS extracted_classes
WHERE TRIM(class_name) != ''
ON CONFLICT (class_name) DO NOTHING;" 2>/dev/null || echo "   ‚ö†Ô∏è  No teacher_load data found yet (will sync after data import)"

# Compter les classes cr√©√©es
classes_count=$(run_sql "SELECT COUNT(*) FROM classes;" | grep -oE '[0-9]+' | tail -1)
echo "   üìä Total classes in database: $classes_count"

# ================================================================
# √âTAPE 1 : Cr√©er la table de contr√¥le des migrations
# ================================================================
echo "üìã Setting up migration control..."

run_sql "
CREATE TABLE IF NOT EXISTS migration_history (
    migration_id SERIAL PRIMARY KEY,
    migration_name VARCHAR(255) UNIQUE NOT NULL,
    executed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    checksum VARCHAR(32)
);"

# ================================================================
# √âTAPE 2 : Fonction pour ex√©cuter les migrations une seule fois
# ================================================================
check_and_run_migration() {
    local migration_name=$1
    local migration_file=$2
    
    echo "üîç Checking migration: $migration_name"
    
    # V√©rifier si la migration a d√©j√† √©t√© ex√©cut√©e
    result=$(run_sql "SELECT COUNT(*) FROM migration_history WHERE migration_name = '$migration_name';")
    count=$(echo $result | grep -oE '[0-9]+' | tail -1)
    
    if [ "$count" = "0" ]; then
        echo "   ‚ñ∂Ô∏è  Running migration: $migration_name"
        
        # Ex√©cuter le fichier SQL
        if run_sql_file "$migration_file"; then
            # Calculer le checksum du fichier
            checksum=$(md5sum "$migration_file" | cut -d' ' -f1)
            
            # Enregistrer dans l'historique
            run_sql "INSERT INTO migration_history (migration_name, checksum) 
                     VALUES ('$migration_name', '$checksum');"
            
            echo "   ‚úÖ Migration completed: $migration_name"
        else
            echo "   ‚ùå Migration failed: $migration_name"
            exit 1
        fi
    else
        echo "   ‚è≠Ô∏è  Migration already executed: $migration_name"
    fi
}

# ================================================================
# √âTAPE 3 : Appliquer le fix de duplication (une seule fois)
# ================================================================
echo "üîß Applying duplication fix..."

# Cr√©er le script de fix temporaire
cat > /tmp/fix_duplication.sql << 'EOF'
BEGIN;

-- Supprimer les doublons existants
WITH duplicates AS (
    SELECT 
        constraint_id,
        ROW_NUMBER() OVER (
            PARTITION BY 
                constraint_type, 
                entity_type, 
                entity_name, 
                MD5(constraint_data::text)
            ORDER BY constraint_id ASC
        ) as rn
    FROM constraints
)
DELETE FROM constraints 
WHERE constraint_id IN (
    SELECT constraint_id 
    FROM duplicates 
    WHERE rn > 1
);

-- Cr√©er un index unique pour pr√©venir les futurs doublons
CREATE UNIQUE INDEX IF NOT EXISTS idx_constraints_unique 
ON constraints (
    constraint_type, 
    entity_type, 
    entity_name, 
    MD5(constraint_data::text)
);

COMMIT;
EOF

check_and_run_migration "fix_constraint_duplication_v1" "/tmp/fix_duplication.sql"

# ================================================================
# √âTAPE 4 : Migrations des contraintes parall√®les (avec protection)
# ================================================================
if [ -f "/app/database/fix_parallel_teaching.sql" ]; then
    echo "üìö Processing parallel teaching constraints..."
    
    # Cr√©er une version s√©curis√©e du script
    cat > /tmp/safe_parallel_teaching.sql << 'EOF'
BEGIN;

-- Reconstruire les groupes parall√®les
TRUNCATE TABLE parallel_groups CASCADE;

INSERT INTO parallel_groups (subject, grade, teachers, class_lists)
SELECT 
    subject,
    grade,
    STRING_AGG(DISTINCT teacher_name, ', ' ORDER BY teacher_name),
    STRING_AGG(DISTINCT class_list, ' | ' ORDER BY class_list)
FROM teacher_load
WHERE class_list IS NOT NULL
  AND class_list LIKE '%,%'
GROUP BY subject, grade
HAVING COUNT(DISTINCT teacher_name) > 1;

-- Remplir les d√©tails (avec protection ON CONFLICT)
DELETE FROM parallel_teaching_details;

WITH parallel_info AS (
    SELECT 
        pg.group_id,
        pg.subject,
        pg.grade,
        unnest(string_to_array(pg.teachers, ', ')) as teacher_name
    FROM parallel_groups pg
)
INSERT INTO parallel_teaching_details (
    group_id, teacher_name, subject, grade, 
    hours_per_teacher, classes_covered
)
SELECT 
    pi.group_id,
    pi.teacher_name,
    pi.subject,
    pi.grade,
    tl.hours,
    tl.class_list
FROM parallel_info pi
JOIN teacher_load tl ON 
    tl.teacher_name = pi.teacher_name 
    AND tl.subject = pi.subject 
    AND tl.grade = pi.grade
WHERE tl.class_list LIKE '%,%';

-- Ajouter les contraintes SANS DUPLICATION
DO $$
DECLARE
    r RECORD;
    existing_id INTEGER;
BEGIN
    FOR r IN (
        SELECT 
            pg.group_id,
            pg.subject,
            pg.grade,
            pg.teachers,
            ptd.hours_per_teacher as hours
        FROM parallel_groups pg
        JOIN parallel_teaching_details ptd ON pg.group_id = ptd.group_id
        GROUP BY pg.group_id, pg.subject, pg.grade, pg.teachers, ptd.hours_per_teacher
    ) LOOP
        -- V√©rifier si la contrainte existe d√©j√†
        SELECT constraint_id INTO existing_id
        FROM constraints
        WHERE constraint_type = 'parallel_teaching'
          AND entity_type = 'group'
          AND entity_name = 'parallel_group_' || r.group_id;
        
        -- Ins√©rer seulement si elle n'existe pas
        IF existing_id IS NULL THEN
            INSERT INTO constraints (
                constraint_type, priority, entity_type, 
                entity_name, constraint_data
            ) VALUES (
                'parallel_teaching',
                1,
                'group',
                'parallel_group_' || r.group_id,
                jsonb_build_object(
                    'group_id', r.group_id,
                    'subject', r.subject,
                    'grade', r.grade,
                    'teachers', string_to_array(r.teachers, ', '),
                    'hours', r.hours,
                    'simultaneous', true
                )
            );
        END IF;
    END LOOP;
END $$;

COMMIT;
EOF
    
    check_and_run_migration "parallel_teaching_constraints_v2" "/tmp/safe_parallel_teaching.sql"
fi

# ================================================================
# √âTAPE 5 : Autres migrations (si n√©cessaire)
# ================================================================
for migration_file in /app/database/migrations/*.sql; do
    if [ -f "$migration_file" ]; then
        migration_name=$(basename "$migration_file" .sql)
        check_and_run_migration "$migration_name" "$migration_file"
    fi
done

# ================================================================
# √âTAPE 6 : Rapport de statut
# ================================================================
echo "üìä Database status report:"

constraint_count=$(run_sql "SELECT COUNT(*) FROM constraints WHERE is_active = true;" | grep -oE '[0-9]+' | tail -1)
parallel_count=$(run_sql "SELECT COUNT(*) FROM constraints WHERE constraint_type = 'parallel_teaching';" | grep -oE '[0-9]+' | tail -1)
migration_count=$(run_sql "SELECT COUNT(*) FROM migration_history;" | grep -oE '[0-9]+' | tail -1)

echo "   üìå Active constraints: $constraint_count"
echo "   üéØ Parallel teaching constraints: $parallel_count"
echo "   ‚úÖ Migrations executed: $migration_count"

# ================================================================
# √âTAPE 7 : D√©marrer l'application
# ================================================================
echo "üöÄ Starting Scheduler AI application..."

cd /app

# D√©terminer dynamiquement le module √† lancer
if [ -f "/app/scheduler_ai/api.py" ]; then
    echo "üì¶ Using package structure (scheduler_ai.api:app)"
    APP_MODULE="scheduler_ai.api:app"
elif [ -f "/app/api.py" ]; then
    echo "üì¶ Using flat structure (api:app)"
    APP_MODULE="api:app"
else
    echo "‚ùå Aucun module API trouv√© (ni scheduler_ai/api.py, ni /app/api.py)"
    ls -la /app
    exit 1
fi

exec gunicorn -k eventlet -w 1 "$APP_MODULE" -b 0.0.0.0:${PORT:-5001} --log-level info